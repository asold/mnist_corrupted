Epoch 0, iter 0, loss: 2.30271577835083
[34m[1mwandb[0m: [33mWARNING[0m Data passed to `wandb.Image` should consist of values in the range [0, 255], image data will be normalized to this range, but behavior will be removed in a future version of wandb.
Epoch 0, iter 100, loss: 0.5060568451881409
Epoch 0, iter 200, loss: 0.8687785267829895
Epoch 0, iter 300, loss: 0.6278203725814819
Epoch 0, iter 400, loss: 0.3158647418022156
Epoch 0, iter 500, loss: 1.5083606243133545
Epoch 0, iter 600, loss: 0.4922012984752655
Epoch 0, iter 700, loss: 0.339680016040802
Epoch 0, iter 800, loss: 0.14725710451602936
Epoch 0, iter 900, loss: 0.13546669483184814
Epoch 1, iter 0, loss: 0.4824044704437256
Epoch 1, iter 100, loss: 0.3201729655265808
Epoch 1, iter 200, loss: 0.25343164801597595
Epoch 1, iter 300, loss: 0.32622528076171875
Epoch 1, iter 400, loss: 0.16861383616924286
Epoch 1, iter 500, loss: 0.8395562171936035
Epoch 1, iter 600, loss: 0.312041699886322
Epoch 1, iter 700, loss: 0.06687621772289276
Epoch 1, iter 800, loss: 0.09342969954013824
Epoch 1, iter 900, loss: 0.08317914605140686
Epoch 2, iter 0, loss: 0.2954005300998688
Epoch 2, iter 100, loss: 0.17909890413284302
Epoch 2, iter 200, loss: 0.4635056257247925
Epoch 2, iter 300, loss: 0.15444214642047882
Epoch 2, iter 400, loss: 0.24708466231822968
Epoch 2, iter 500, loss: 0.9807947874069214
Epoch 2, iter 600, loss: 0.07832439243793488
Epoch 2, iter 700, loss: 0.1332865059375763
Epoch 2, iter 800, loss: 0.04006098210811615
Epoch 2, iter 900, loss: 0.08413480222225189
C:\Users\asold\DTU_Local\MLOps\dtu_mlops\mnist_exercise\.venv\Lib\site-packages\sklearn\utils\_plotting.py:28: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  _, ax = plt.subplots()
Epoch 3, iter 0, loss: 0.14188122749328613
Epoch 3, iter 100, loss: 0.06986517459154129
Epoch 3, iter 200, loss: 0.30452194809913635
Epoch 3, iter 300, loss: 0.11897540837526321
Epoch 3, iter 400, loss: 0.08324277400970459
Epoch 3, iter 500, loss: 0.5257280468940735
Epoch 3, iter 600, loss: 0.1739169955253601
Epoch 3, iter 700, loss: 0.06197395920753479
Epoch 3, iter 800, loss: 0.04189001023769379
Epoch 3, iter 900, loss: 0.05518875643610954
Epoch 4, iter 0, loss: 0.25390446186065674
Epoch 4, iter 100, loss: 0.08399470895528793
Epoch 4, iter 200, loss: 0.1687932312488556
Epoch 4, iter 300, loss: 0.3630848526954651
Epoch 4, iter 400, loss: 0.11647824198007584
Epoch 4, iter 500, loss: 0.16711989045143127
Epoch 4, iter 600, loss: 0.27162328362464905
Epoch 4, iter 700, loss: 0.06960052996873856
Epoch 4, iter 800, loss: 0.025738904252648354
Epoch 4, iter 900, loss: 0.07002764940261841
