Epoch 0, iter 0, loss: 2.32523250579834
[34m[1mwandb[0m: [33mWARNING[0m Data passed to `wandb.Image` should consist of values in the range [0, 255], image data will be normalized to this range, but behavior will be removed in a future version of wandb.
Epoch 0, iter 100, loss: 0.4788759648799896
Epoch 0, iter 200, loss: 0.9240404367446899
Epoch 0, iter 300, loss: 0.6486657857894897
Epoch 0, iter 400, loss: 0.4839535057544708
Epoch 0, iter 500, loss: 1.2600860595703125
Epoch 0, iter 600, loss: 0.5485175251960754
Epoch 0, iter 700, loss: 0.3422274887561798
Epoch 0, iter 800, loss: 0.21774563193321228
Epoch 0, iter 900, loss: 0.20966315269470215
Epoch 1, iter 0, loss: 0.34843674302101135
Epoch 1, iter 100, loss: 0.18547941744327545
Epoch 1, iter 200, loss: 0.5301840305328369
Epoch 1, iter 300, loss: 0.13961419463157654
Epoch 1, iter 400, loss: 0.12258701026439667
Epoch 1, iter 500, loss: 1.182438611984253
Epoch 1, iter 600, loss: 0.38596540689468384
Epoch 1, iter 700, loss: 0.09835556894540787
Epoch 1, iter 800, loss: 0.10229763388633728
Epoch 1, iter 900, loss: 0.08296412974596024
Epoch 2, iter 0, loss: 0.17424115538597107
Epoch 2, iter 100, loss: 0.07660479098558426
Epoch 2, iter 200, loss: 0.34383949637413025
Epoch 2, iter 300, loss: 0.4597085118293762
Epoch 2, iter 400, loss: 0.08222821354866028
Epoch 2, iter 500, loss: 0.5431582927703857
Epoch 2, iter 600, loss: 0.17473489046096802
Epoch 2, iter 700, loss: 0.10892384499311447
Epoch 2, iter 800, loss: 0.07254776358604431
Epoch 2, iter 900, loss: 0.08639297634363174
C:\Users\asold\DTU_Local\MLOps\dtu_mlops\mnist_exercise\.venv\Lib\site-packages\sklearn\utils\_plotting.py:28: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  _, ax = plt.subplots()
Epoch 3, iter 0, loss: 0.1785108745098114
Epoch 3, iter 100, loss: 0.13181252777576447
Epoch 3, iter 200, loss: 0.2725745141506195
Epoch 3, iter 300, loss: 0.204379141330719
Epoch 3, iter 400, loss: 0.06557620316743851
Epoch 3, iter 500, loss: 0.5880943536758423
Epoch 3, iter 600, loss: 0.18088483810424805
Epoch 3, iter 700, loss: 0.07980122417211533
Epoch 3, iter 800, loss: 0.11926432698965073
Epoch 3, iter 900, loss: 0.06669926643371582
Epoch 4, iter 0, loss: 0.2987712621688843
Epoch 4, iter 100, loss: 0.20939648151397705
Epoch 4, iter 200, loss: 0.1846529245376587
Epoch 4, iter 300, loss: 0.1364334225654602
Epoch 4, iter 400, loss: 0.10911434143781662
Epoch 4, iter 500, loss: 0.2980334460735321
Epoch 4, iter 600, loss: 0.2888965904712677
Epoch 4, iter 700, loss: 0.05202195793390274
Epoch 4, iter 800, loss: 0.01240742951631546
Epoch 4, iter 900, loss: 0.024717899039387703
